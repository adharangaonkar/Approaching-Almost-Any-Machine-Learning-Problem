{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd04649",
   "metadata": {},
   "source": [
    "When we have a dataset like as shown, we can build a simple model\n",
    "that’s trained on all features except “f3”. Thus, you will be creating a model that\n",
    "predicts “f3” when it’s not known or not available in training. I can’t say if this kind\n",
    "of model is going to give you an excellent performance but might be able to handle\n",
    "those missing values in test set or live data and one can’t say without trying just like\n",
    "everything else when it comes to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422c9a2",
   "metadata": {},
   "source": [
    "If you have a fixed test set, you can add your test data to training to know about the\n",
    "categories in a given feature. This is very similar to semi-supervised learning in\n",
    "which you use data which is not available for training to improve your model. This\n",
    "will also take care of rare values that appear very less number of times in training\n",
    "data but are in abundance in test data. Your model will be more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f77525",
   "metadata": {},
   "source": [
    "Many people think that this idea overfits. It may or may not overfit. There is a\n",
    "simple fix for that. **If you design your cross-validation in such a way that it\n",
    "replicates the prediction process when you run your model on test data, then it’s\n",
    "never going to overfit**. It means that the first step should be the separation of folds,\n",
    "and in each fold, you should apply the same pre-processing that you want to apply\n",
    "to test data. Suppose you want to concatenate training and test data, then in each\n",
    "fold you must concatenate training and validation data and also make sure that your\n",
    "validation dataset replicates the test set. In this specific case, you must design your\n",
    "validation sets in such a way that it has categories which are “unseen” in the training\n",
    "set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d62434",
   "metadata": {},
   "source": [
    "How this works is can be understood easily by looking at figure 4 and the following\n",
    "code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d05527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "# read training data\n",
    "train = pd.read_csv(\"../cat_train.csv\")\n",
    "#read test data\n",
    "test = pd.read_csv(\"../cat_test.csv\")\n",
    "# create a fake target column for test data\n",
    "# since this column doesn't exist\n",
    "test.loc[:, \"target\"] = -1\n",
    "# concatenate both training and test data\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "# make a list of features we are interested in\n",
    "# id and target is something we should not encode\n",
    "features = [x for x in train.columns if x not in [\"id\", \"target\"]]\n",
    "# loop over the features list\n",
    "for feat in features:\n",
    "# create a new instance of LabelEncoder for each feature\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "# note the trick here\n",
    "# since its categorical data, we fillna with a string\n",
    "# and we convert all the data to string type\n",
    "# so, no matter its int or float, its converted to string\n",
    "# int/float but categorical!!!\n",
    "temp_col = data[feat].fillna(\"NONE\").astype(str).values\n",
    "# we can use fit_transform here as we do not\n",
    "# have any extra test data that we need to\n",
    "# transform on separately\n",
    "data.loc[:, feat] = lbl_enc.fit_transform(temp_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51819fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and test data again\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5da02",
   "metadata": {},
   "source": [
    "This trick works when you have a problem where you already have the test dataset.\n",
    "It must be noted that this trick will not work in a live setting. For example, let’s say\n",
    "you are in a company that builds a real-time bidding solution (RTB). RTB systems\n",
    "bid on every user they see online to buy ad space. The features that can be used for\n",
    "such a model may include pages viewed in a website. Let’s assume that features are\n",
    "the last five categories/pages visited by the user. In this case, if the website\n",
    "introduces new categories, we will no longer be able to predict accurately. Our\n",
    "model, in this case, will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f0e04",
   "metadata": {},
   "source": [
    "A situation like this can be avoided by using an\n",
    "**“unknown”** category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f3d6d",
   "metadata": {},
   "source": [
    "In our cat-in-the-dat dataset, we already have unknowns in ord_2 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640688d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../cat_train.csv')\n",
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d854540",
   "metadata": {},
   "source": [
    "We can treat “NONE” as unknown. So, if during live testing, we get new categories\n",
    "that we have not seen before, we will mark them as “NONE”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335dec5",
   "metadata": {},
   "source": [
    "So, you can either assume that your test data will have the same categories as\n",
    "training or you can introduce a rare or unknown category to training to take care of\n",
    "new categories in test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb778695",
   "metadata": {},
   "source": [
    "Let’s see the value counts in ord_4 column after filling NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95767f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546dfa5",
   "metadata": {},
   "source": [
    "We see that some values appear only a couple thousand times, and some appear\n",
    "almost 40000 times. NaNs are also seen a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124fa9aa",
   "metadata": {},
   "source": [
    "We can now define our criteria for calling a value “rare”. Let’s say the requirement\n",
    "for a value being rare in this column is a count of less than 2000. So, it seems, J and\n",
    "L can be marked as rare values. With pandas, it is quite easy to replace categories\n",
    "based on count threshold. Let’s take a look at how it’s done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e27f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ord_4 = df.ord_4.fillna(\"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23555719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000, \"ord_4\"] = \"RARE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c6516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759190c",
   "metadata": {},
   "source": [
    "We say that wherever the value count for a certain category is less than 2000,\n",
    "replace it with rare. So, now, when it comes to test data, all the new, unseen\n",
    "categories will be mapped to “RARE”, and all missing values will be mapped to\n",
    "“NONE”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6867da2",
   "metadata": {},
   "source": [
    "This approach will also ensure that the model works in a live setting, even if you\n",
    "have new categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e896bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series",
   "language": "python",
   "name": "time_series"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
